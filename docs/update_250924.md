
# Análisis Filogenético Dual para C. auris

**Objetivo:** Implementar dos estrategias filogenéticas complementarias en el pipeline de Snakemake:

### 1. **Árbol Triage (Rápido - Assembly-to-assembly)**

- **Propósito:** Análisis rápido para clasificación inicial de cepas
- **Herramientas:**
    - `Mash/sourmash`: Comparación rápida basada en k-mers de genomas completos
    - `fastANI`: Cálculo de Average Nucleotide Identity (ANI)
    - `nucmer`: Alineamiento genoma completo (opcional)
- **Tiempo:** ~5-10 minutos
- **Output:** Árbol de distancias genómicas para identificación rápida de clados

### 2. **Árbol Filogenético Robusto (Lento - Basado en ortólogos)**

- **Propósito:** Filogenia precisa para publicación/análisis detallado
- **Workflow:**
    1. `funannotate`: Anotación completa de genomas (predict + annotate)
    2. `OrthoFinder`: Identificación de ortólogos single-copy
    3. `IQ-TREE`: Construcción de árbol ML con modelos evolutivos
    4. `ETE3`: Visualización profesional
- **Tiempo:** ~2-4 horas
- **Output:** Árbol filogenético robusto basado en genes ortólogos

**Estructura de directorios:**

```
03.5_triage/       # Árboles rápidos
03.6_funannotate/  # Anotaciones
03.7_orthofinder/  # Análisis de ortólogos  
03.8_phylogeny/    # Árboles finales
```

**Casos de uso:**

- Triage: Identificación rápida de brotes, clasificación inicial
- Robusto: Publicaciones, análisis evolutivos, identificación precisa de clados

Ambos enfoques son complementarios: el triage permite decisiones rápidas mientras se ejecuta el análisis completo.


IMPORTANTE, PARA TODAS LAS REGLAS se emplea ambiente `envs/epicandi_phylonew.yml`

Y es importante primero su setup, y que todas las reglas tengan una dependencia para que no empiecen si este ambiente está bien instalado.


## Árbol triage assembly 2 assembly

 Enfoque de "assembly-to-assembly" para un triaje rápido es excelente, y las herramientas que has elegido son perfectas para ello. 
A partir del código:

```bash
ls all_assemblies/
EPI003102.fasta  EPI003135.fasta  EPI003361.fasta

############################################################
# REGLA SETUP FUNANNOTATE

# 1. Alineamiento all-vs-all de ensamblajes con nucmer
mkdir -p nucmer_alignments
for query in all_assemblies/*.fasta; do
    for ref in all_assemblies/*.fasta; do
        if [[ "$query" != "$ref" ]]; then
            qname=$(basename $query .fasta)
            rname=$(basename $ref .fasta)
            nucmer --maxmatch --nosimplify \
                $ref $query \
                -p nucmer_alignments/${rname}_vs_${qname}
        fi
    done
done

# 2. Calcular ANI (Average Nucleotide Identity)
ls all_assemblies/*.fasta > genome_list.txt
fastANI --ql genome_list.txt --rl genome_list.txt \
    -o ani_matrix.txt --matrix

# 3. Usar Sourmash para comparación rápida de k-mers
sourmash sketch dna -p k=31,scaled=1000 all_assemblies/*.fasta
mv *.fasta.sig all_assemblies
sourmash compare all_assemblies/*.fasta.sig \
    -o sourmash_matrix.csv --csv T

# 4. Crear árbol basado en distancias de Mash
mash triangle all_assemblies/*.fasta > mash_distances.txt

cat mash_distances.txt
        3
all_assemblies/EPI003102.fasta
all_assemblies/EPI003135.fasta  0.000119496
all_assemblies/EPI003361.fasta  2.38274e-05     0.000143503

cat > mash2newick.py << 'EOF'
#!/usr/bin/env python
import sys
import numpy as np
from scipy.cluster.hierarchy import linkage, to_tree
from scipy.spatial.distance import squareform

def parse_mash_triangle(file_path):
    """
    Lee la salida de 'mash triangle' y devuelve nombres y matriz cuadrada de distancias.
    """
    with open(file_path, 'r') as f:
        lines = [line.strip() for line in f if line.strip()]

    # Si la primera línea es el número de muestras, se descarta
    try:
        int(lines[0])
        proc_lines = lines[1:]
    except ValueError:
        proc_lines = lines

    names = [proc_lines[0].split('\t')[0]]
    distances = []
    
    for line in proc_lines[1:]:
        parts = line.split('\t')
        names.append(parts[0])
        row_distances = [float(d) for d in parts[1:]]
        distances.append(row_distances)

    num_items = len(names)
    dist_matrix = np.zeros((num_items, num_items))

    row_idx = 0
    for i in range(1, num_items):
        for j in range(i):
            dist_matrix[i, j] = distances[row_idx][j]
            dist_matrix[j, i] = distances[row_idx][j]
        row_idx += 1
        
    return names, dist_matrix

def scipy_tree_to_newick(node, leaf_names):
    """
    Convierte un nodo SciPy a Newick recursivamente.
    """
    if node.is_leaf():
        return f"{leaf_names[node.id]}"
    else:
        left = scipy_tree_to_newick(node.get_left(), leaf_names)
        right = scipy_tree_to_newick(node.get_right(), leaf_names)

        left_len = node.dist - node.get_left().dist
        right_len = node.dist - node.get_right().dist

        return f"({left}:{left_len:.6f},{right}:{right_len:.6f})"

def main(mash_file):
    names, dist_matrix = parse_mash_triangle(mash_file)

    # Convertir a formato condensado que espera linkage()
    condensed_dist_matrix = squareform(dist_matrix)

    # Clustering jerárquico tipo UPGMA
    linkage_matrix = linkage(condensed_dist_matrix, method="average")

    # Convertir a árbol SciPy
    scipy_tree = to_tree(linkage_matrix, rd=False)

    # Convertir a Newick
    newick_string = scipy_tree_to_newick(scipy_tree, names)
    print(f"{newick_string};")

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Uso: python mash2newick.py <archivo_distancias_mash>")
        sys.exit(1)
    
    main(sys.argv[1])
EOF


python mash2newick.py mash_distances.txt > tree.nwk


cat > ete3_draw.py << 'EOF'
#!/usr/bin/env python
import os
from ete3 import Tree, TreeStyle, NodeStyle

os.environ["QT_QPA_PLATFORM"] = "offscreen"

# Cargar el árbol (Newick con longitudes de rama)
t = Tree("tree.nwk", format=1)

# Estilo de nodos (para mostrar nombres + longitudes de rama)
for n in t.traverse():
    nstyle = NodeStyle()
    nstyle["shape"] = "circle"
    nstyle["size"] = 5
    nstyle["fgcolor"] = "black"
    n.set_style(nstyle)

    # Mostrar longitudes de rama
    if not n.is_leaf():
        n.add_features(name=f"dist={n.dist:.4f}")

# Configurar estilo del árbol
ts = TreeStyle()
ts.show_leaf_name = True        # Mostrar nombres de las hojas
ts.show_branch_length = True    # Mostrar longitudes de rama
ts.show_branch_support = True   # Mostrar soportes (si hubiera bootstraps)
ts.scale = 50                   # Escala visual (ajusta el tamaño)

# Renderizar a SVG y PNG
t.render("tree.svg", tree_style=ts)
t.render("tree.png", tree_style=ts)
EOF

python ete3_draw.py
```

## Nombres de Reglas con Prefijo triage
triage_fastani_matrix: Calcula la matriz de ANI.
triage_sourmash_sketch: Crea las firmas de k-mers.
triage_sourmash_compare: Compara las firmas.
triage_mash_triangle: Genera la matriz de distancias de Mash.
triage_mash_to_newick: Convierte la matriz a formato Newick.
triage_visualize_tree: Dibuja el árbol final.

Se propone este código remplazando fastAni por nucmer para más rapidez.

```bash
# --- 3. REGLAS DE ANÁLISIS ---

rule fastani_matrix:
    input:
        expand("all_assemblies/{sample}.fasta", sample=SAMPLES)
    output:
        matrix="fastani/ani_matrix.txt",
        file_list="fastani/genome_list.txt"
    log:
        "logs/fastani.log"
    shell:
        """
        ls -d "$PWD"/all_assemblies/*.fasta > {output.file_list}
        fastANI --ql {output.file_list} --rl {output.file_list} -o {output.matrix} --matrix &> {log}
        """

rule sourmash_sketch:
    input:
        "all_assemblies/{sample}.fasta"
    output:
        "sourmash/sketches/{sample}.sig"
    log:
        "logs/sourmash_sketch/{sample}.log"
    params:
        k=31,
        scale=1000
    shell:
        """
        sourmash sketch dna -p k={params.k},scaled={params.scale} -o {output} {input} &> {log}
        """

rule sourmash_compare:
    input:
        expand("sourmash/sketches/{sample}.sig", sample=SAMPLES)
    output:
        "sourmash/sourmash_matrix.csv"
    log:
        "logs/sourmash_compare.log"
    threads: 8
    shell:
        """
        sourmash compare -o {output} --csv {input} -k 31 -p {threads} &> {log}
        """

rule mash_triangle:
    input:
        expand("all_assemblies/{sample}.fasta", sample=SAMPLES)
    output:
        "mash/mash_distances.txt"
    log:
        "logs/mash.log"
    threads: 8
    shell:
        """
        mash triangle -p {threads} {input} > {output} 2> {log}
        """

rule mash_to_newick:
    input:
        "mash/mash_distances.txt"
    output:
        "mash/tree.nwk"
    log:
        "logs/mash2newick.log"
    shell:
        """
        # Tu script de Python para convertir la matriz de Mash a Newick
        cat > mash2newick.py << 'EOF'
#!/usr/bin/env python
import sys
import numpy as np
from scipy.cluster.hierarchy import linkage, to_tree
from scipy.spatial.distance import squareform

def parse_mash_triangle(file_path):
    with open(file_path, 'r') as f:
        lines = [line.strip() for line in f if line.strip()]
    try:
        int(lines[0])
        proc_lines = lines[1:]
    except ValueError:
        proc_lines = lines
    names = [proc_lines[0].split('\t')[0]]
    distances = []
    for line in proc_lines[1:]:
        parts = line.split('\t')
        names.append(parts[0])
        row_distances = [float(d) for d in parts[1:]]
        distances.append(row_distances)
    num_items = len(names)
    dist_matrix = np.zeros((num_items, num_items))
    row_idx = 0
    for i in range(1, num_items):
        for j in range(i):
            dist_matrix[i, j] = distances[row_idx][j]
            dist_matrix[j, i] = distances[row_idx][j]
        row_idx += 1
    return names, dist_matrix

def scipy_tree_to_newick(node, leaf_names):
    if node.is_leaf():
        return f"{leaf_names[node.id]}"
    else:
        left = scipy_tree_to_newick(node.get_left(), leaf_names)
        right = scipy_tree_to_newick(node.get_right(), leaf_names)
        left_len = node.dist - node.get_left().dist
        right_len = node.dist - node.get_right().dist
        return f"({left}:{left_len:.6f},{right}:{right_len:.6f})"

def main(mash_file):
    names, dist_matrix = parse_mash_triangle(mash_file)
    condensed_dist_matrix = squareform(dist_matrix)
    linkage_matrix = linkage(condensed_dist_matrix, method="average")
    scipy_tree = to_tree(linkage_matrix, rd=False)
    newick_string = scipy_tree_to_newick(scipy_tree, names)
    print(f"{newick_string};")

if __name__ == "__main__":
    main(sys.argv[1])
EOF
        python mash2newick.py {input} > {output} 2> {log}
        """

rule visualize_tree:
    input:
        "mash/tree.nwk"
    output:
        png="mash/tree.png",
        svg="mash/tree.svg"
    log:
        "logs/ete3_draw.log"
    shell:
        """
        # Tu script de Python para dibujar el árbol con ETE3
        cat > ete3_draw.py << 'EOF'
#!/usr/bin/env python
import os
from ete3 import Tree, TreeStyle, NodeStyle
os.environ["QT_QPA_PLATFORM"] = "offscreen"
t = Tree("{input}", format=1)
for n in t.traverse():
    nstyle = NodeStyle()
    nstyle["shape"] = "circle"
    nstyle["size"] = 5
    nstyle["fgcolor"] = "black"
    n.set_style(nstyle)
ts = TreeStyle()
ts.show_leaf_name = True
ts.show_branch_length = True
t.render("{output.svg}", tree_style=ts)
t.render("{output.png}", tree_style=ts)
EOF
        python ete3_draw.py &> {log}
        """
```


## Árbol con anotaciones ortologos

Se emplea ambiente `envs/epicandi_phylonew.yml`

```bash
############################################################
# REGLA SETUP FUNANNOTATE

#################### hacer permanente base de datos en conda !!!!!!!
#set ENV variable for $FUNANNOTATE_DB

# Get the absolute path to the project directory (where this script is located)
PROJECT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )
DB_DIR="${PROJECT_DIR}/resources/funannotate_db"
mkdir -p "$DB_DIR"

# Temporarily set ENV variable for the setup command to use the correct path
export FUNANNOTATE_DB="$DB_DIR"
funannotate setup --update --force

# --- CONDITIONALLY SET ENV VARIABLES FOR THE CONDA ENV ---
# GENEMARK  se da o no por params en snakemake
# Se puede dar o no dar, si se da en parámetros, entonces se configura su path
GENEMARK_DIR="/home/asanzc/epicandi/resources/genemark/gmes_linux_64_4"

ACTIVATE_DIR="${CONDA_PREFIX}/etc/conda/activate.d"
DEACTIVATE_DIR="${CONDA_PREFIX}/etc/conda/deactivate.d"
mkdir -p "$ACTIVATE_DIR" "$DEACTIVATE_DIR"

# Create/overwrite the activation script with the mandatory variable
echo "export FUNANNOTATE_DB=${DB_DIR}" > "${ACTIVATE_DIR}/env_vars.sh"

# Create/overwrite the deactivation script
echo "unset FUNANNOTATE_DB" > "${DEACTIVATE_DIR}/env_vars.sh"

# Conditionally add GeneMark path if the variable is not empty
if [ -n "$GENEMARK_DIR" ]; then
    echo "INFO: GENEMARK_DIR is set. Adding it to the Conda environment variables."
    echo "export GENEMARK_PATH=${GENEMARK_DIR}" >> "${ACTIVATE_DIR}/env_vars.sh"
    echo "unset GENEMARK_PATH" >> "${DEACTIVATE_DIR}/env_vars.sh"
else
    echo "INFO: GENEMARK_DIR is not set. Skipping."
fi

# Descargamos la base de datos saccharomycetes_odb10 y la ponemos en el directorio de funannotate
# DOWNLOAD saccharomycetes_odb10
wget https://busco-data.ezlab.org/v5/data/lineages/saccharomycetes_odb10.2024-01-08.tar.gz -O "$DB_DIR/saccharomycetes_odb10.2024-01-08.tar.gz"
# Descomprimirla
tar -xzvf "$DB_DIR/saccharomycetes_odb10.2024-01-08.tar.gz" -C $DB_DIR

# SET PERMISSIONS FOR AUXILIARY SCRIPTS 

# Imporante arreglar permisos, cuando se instala desde conda, parece que hay problemas en algunos archivos.

# Find the aux_scripts directory dynamically within the Conda prefix
AUX_SCRIPTS_DIR=$(find "${CONDA_PREFIX}/lib/" -type d -path "*/funannotate/aux_scripts" | head -n 1)

if [ -n "$AUX_SCRIPTS_DIR" ]; then
    chmod +x "${AUX_SCRIPTS_DIR}"/*
else
    echo "ERROR: Could not find the funannotate/aux_scripts directory." >&2
   # exit 1
fi


############################################################
# REGLA CORRER FUNANNOTATE

# -----------------------------------------------------------------------------
# SCRIPT PARA LA ANOTACIÓN DE GENOMAS DE CANDIDA AURIS CON FUNANNOTATE
#
# Este script ejecuta el pipeline completo:
# 1. Prepara los directorios.
# 2. Para cada ensamblaje:
#    a. Ordena los contigs (sort).
#    b. Enmascara las repeticiones (mask).
#    c. Predice los genes (predict).
#    d. Busca dominios de proteínas con InterProScan (iprscan).
#    e. Unifica toda la anotación funcional (annotate).
# -----------------------------------------------------------------------------

# Variables (¡ajusta la ruta de entrada!)

SAMPLE_ID="EPI003361"
SAMPLE_ID="EPI003102"
SAMPLE_ID="EPI003135"

THREADS=32
SPECIES="Candida auris"
BUSCO_DB="saccharomycetes_odb10"
assembly="output/02_assembly/02.3_consensus/${SAMPLE_ID}.fasta"
SAMPLE_OUTDIR="output/03_characterization/03.6_funannotate/$SAMPLE_ID"

LOG_OUTDIR="output/logs/03_characterization/03.6_funannotate/$SAMPLE_ID"  

mkdir -p $SAMPLE_OUTDIR $LOG_OUTDIR

cd $SAMPLE_OUTDIR

# --- PASO a: ORDENAR CONTIGS (SORT) ---
funannotate sort -i "$assembly" -o "${SAMPLE_ID}_clean.fasta" --minlen 500

# --- PASO b: ENMASCARAR REPETICIONES (MASK) ---
funannotate mask -i "${SAMPLE_ID}_clean.fasta" -o  "${SAMPLE_ID}_clean_masked.fasta" --cpus "$THREADS"

# --- PASO c: PREDICCIÓN DE GENES (PREDICT) --
funannotate predict -i "${SAMPLE_ID}_clean_masked.fasta" -o . \
    --species "$SPECIES" --strain "$SAMPLE_ID" \
    --busco_db "$BUSCO_DB" --cpus "$THREADS"

# --- PASO d: ANOTACIÓN FUNCIONAL EXTERNA (IPRSCAN) ---
funannotate iprscan -i . -m docker --cpus "$THREADS"

# --- PASO e: ANOTACIÓN FINAL (ANNOTATE) ---
funannotate annotate -i . --busco_db "$BUSCO_DB" --cpus "$THREADS"



############################################################
# REGLA ORTHOFINDER_PROTEOMES

# Variables
SAMPLES=("EPI003361" "EPI003102" "EPI003135")
THREADS=32
BASE_DIR="output/03_characterization"
ORTHO_DIR="$BASE_DIR/03.7_orthofinder"
PHYLO_DIR="$BASE_DIR/03.8_phylogeny"

# Create directory structure
mkdir -p $ORTHO_DIR/{proteomes,results}
mkdir -p $PHYLO_DIR/{alignments,trees,figures}


# JUNTAMOS PROTEOMA !!
# Extract proteins from your annotations
for SAMPLE_ID in "${SAMPLES[@]}"; do
    echo "[$(date)] Extracting proteins from $SAMPLE_ID..."
    
    # From funannotate output
    PROTEIN_FILE="$BASE_DIR/03.6_funannotate/${SAMPLE_ID}/predict_results/*.proteins.fa"
    
    if [ -f $PROTEIN_FILE ]; then
        cp $PROTEIN_FILE $ORTHO_DIR/proteomes/${SAMPLE_ID}.faa
        # Clean headers for OrthoFinder
        sed -i "s/ .*//g" $ORTHO_DIR/proteomes/${SAMPLE_ID}.faa
        echo "  ✓ ${SAMPLE_ID}: $(grep -c ">" $ORTHO_DIR/proteomes/${SAMPLE_ID}.faa) proteins"
    else
        echo "  ✗ Warning: No proteins found for ${SAMPLE_ID}"
    fi
done

# ADD REFERENCE GENOMES (for better tree topology and rooting)
echo "[$(date)] Adding reference genomes..."
cd $ORTHO_DIR/proteomes

# Añadiremos 2 de forma manual, una referencia, que en este caso sería de las nuestras, de la más cercana según el análisis de fastANI, en este caso pongo por ejemplo esta referencia:

# C. auris reference (Clade I - South Asian)
echo "  Downloading C. auris B8441 (reference)..."
wget -q -O B8441_ref.faa.gz "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/775/015/GCF_002775015.1_Cand_auris_B8441_V2/GCF_002775015.1_Cand_auris_B8441_V2_protein.faa.gz"
gunzip B8441_ref.faa.gz

# Como OUTGRUPO ponemos otra
# Optional: C. haemulonii as outgroup (closest species to C. auris)
echo "  Downloading C. haemulonii (outgroup)..."
wget -q -O Chaemulonii_out.faa.gz "https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/926/085/GCF_002926085.2_Cand_haemulonii/GCF_002926085.2_Cand_haemulonii_protein.faa.gz"
gunzip Chaemulonii_out.faa.gz

# USAR REFERENCIAS
# - **En OrthoFinder**:
#     - Mejora la identificación de ortólogos
#     - Ayuda a distinguir parálogos
#     - Proporciona más datos para el árbol de especies
# - **El outgroup (C. haemulonii)**:
#     - Permite rootear el árbol correctamente
#     - Ayuda a determinar la dirección evolutiva

############################################################
# REGLA ORTHOFINDER_ANALYSIS

orthofinder \
    -f $ORTHO_DIR/proteomes \
    -t $THREADS \
    -M msa \
    -S diamond_ultra_sens \
    -A mafft \
    -T fasttree \
    -o $ORTHO_DIR/results \
    2>&1 | tee $ORTHO_DIR/orthofinder.log
    
############################################################
# REGLA ORTHOFINDER_IQTREE

# Find OrthoFinder results
ORTHO_RESULTS=$(find $ORTHO_DIR/results -maxdepth 1 -name "Results_*" -type d | head -1)

# Option A: Use OrthoFinder species tree (FASTEST)
# echo "Option A: Using OrthoFinder species tree..."
# cp $ORTHO_RESULTS/Species_Tree/SpeciesTree_rooted.txt $PHYLO_DIR/trees/cauris_orthofinder.tree

# Option B: Concatenated alignment of single-copy orthologs (MORE ROBUST)
echo "Option B: Building concatenated alignment tree..."

# Extract and concatenate single-copy orthologs
python3 << 'PYTHON'
import os
import sys
from pathlib import Path

ortho_dir = os.environ.get('ORTHO_RESULTS')
phylo_dir = os.environ.get('PHYLO_DIR')
single_copy_dir = f"{ortho_dir}/Single_Copy_Orthologue_Sequences"

if not os.path.exists(single_copy_dir):
    print("No single-copy orthologs found")
    sys.exit(1)

# Count orthologs
og_files = list(Path(single_copy_dir).glob("OG*.fa"))
print(f"Found {len(og_files)} single-copy orthologs")

# Concatenate (simplified version)
concat_seqs = {}
for og_file in og_files[:100]:  # Use first 100 for speed
    with open(og_file) as f:
        current_id = None
        for line in f:
            if line.startswith('>'):
                current_id = line[1:].split()[0].split('|')[0]
                if current_id not in concat_seqs:
                    concat_seqs[current_id] = ""
            else:
                concat_seqs[current_id] += line.strip()

# Write concatenated
outfile = f"{phylo_dir}/alignments/concatenated.fasta"
with open(outfile, 'w') as out:
    for taxon, seq in concat_seqs.items():
        out.write(f">{taxon}\n{seq}\n")
print(f"Concatenated alignment: {len(concat_seqs)} taxa, {len(seq)} sites")
PYTHON

# Run IQ-TREE on concatenated alignment
cd $PHYLO_DIR/alignments
if [ -f "concatenated.fasta" ]; then
    echo "Running IQ-TREE..."
    iqtree \
        -s concatenated.fasta \
        -m MFP \
        -bb 1000 \
        -nt AUTO \
        -ntmax $THREADS \
        -pre ../trees/cauris_iqtree \
        -quiet
    echo "  ✓ IQ-TREE completed"
fi
    

# OrthoFinder genera:
# - Orthogroups (grupos de genes ortólogos)
# - Single-copy orthologs (mejores para filogenia)
# - Species tree (árbol de especies)


############################################################
# REGLA ORTHOFINDER_RENDER_TREE

# Create visualization script
cat > $PHYLO_DIR/visualize.py << 'PYTHON'
#!/usr/bin/env python3
from ete3 import Tree, TreeStyle, NodeStyle, TextFace
import sys

# Configuration
tree_file = "trees/cauris_iqtree.treefile"  # or cauris_orthofinder.tree
output_prefix = "figures/cauris_phylogeny"

# Load tree
try:
    tree = Tree(tree_file)
except:
    tree = Tree("trees/cauris_orthofinder.tree")

# Strain information
strain_info = {
    "EPI003361": {"color": "#E74C3C", "clade": "Unknown"},
    "EPI003102": {"color": "#3498DB", "clade": "Unknown"},
    "EPI003135": {"color": "#2ECC71", "clade": "Unknown"},
    "B8441_ref": {"color": "#F39C12", "clade": "Clade I"},
    "Chaemulonii_out": {"color": "#95A5A6", "clade": "Outgroup"}
}

# Root at outgroup if present
for leaf in tree.get_leaves():
    if "Chaemulonii" in leaf.name:
        tree.set_outgroup(leaf)
        break

# Style tree
ts = TreeStyle()
ts.show_leaf_name = True
ts.scale = 100
ts.branch_vertical_margin = 10

# Color nodes
for node in tree.traverse():
    if node.is_leaf():
        strain = node.name.split('.')[0]
        if strain in strain_info:
            ns = NodeStyle()
            ns["bgcolor"] = strain_info[strain]["color"]
            ns["size"] = 15
            node.set_style(ns)

# Save tree
tree.render(f"{output_prefix}.png", w=800, h=600, tree_style=ts, dpi=300)
tree.render(f"{output_prefix}.pdf", tree_style=ts)

# Print ASCII tree
print("\n=== TREE TOPOLOGY ===")
print(tree.get_ascii(show_internal=True))

# Print statistics
print("\n=== TREE STATISTICS ===")
print(f"Number of leaves: {len(tree.get_leaves())}")
print(f"Samples included: {[l.name for l in tree.get_leaves()]}")
PYTHON

cd $PHYLO_DIR
python3 visualize.py
````
